{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72008247",
   "metadata": {},
   "source": [
    "# Problem Statement:\n",
    "\n",
    "Identifying pediatric obesity from Electronic Health Record data is a challenge. It is especially arduous given that ICD10 codes for obesity are undercoded. In this exercise, I intend to develop a machine learning methodology that uses patient-level information for demographic characteristics(sex, age, region), type of insurance, co-occurring conditions and medical expenditures associated with weight status to predict obesity. Data includes individuals aged 2 to 19 years and has been obtained from deidentified IQVIA's AEMR and PharMetrics Plus commercial claims data.\n",
    "\n",
    "This is a work in progress as model needs to be futher improved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09c314c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the libraries\n",
    "import pandas as pd\n",
    "import pandasql as ps\n",
    "#display options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6fab8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import textwrap\n",
    "from IPython.display import display\n",
    "\n",
    "from patsy import dmatrices\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score\n",
    "\n",
    "import pygwalker as pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c014e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable inline plotting for graphics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f2d4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.11 (default, Jul 27 2021, 09:42:29) [MSC v.1916 64 bit (AMD64)] \n",
      "\n",
      "Pandas version: 1.3.4 \n",
      "\n",
      "Matplotlib version: 3.5.0 \n",
      "\n",
      "Numpy version: 1.20.3 \n",
      "\n",
      "Seaborn version: 0.11.1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get Version information\n",
    "print(textwrap.fill(sys.version),'\\n')\n",
    "print(\"Pandas version: {0}\".format(pd.__version__),'\\n')\n",
    "print(\"Matplotlib version: {0}\".format(matplotlib.__version__),'\\n')\n",
    "print(\"Numpy version: {0}\".format(np.__version__),'\\n')\n",
    "print(\"Seaborn version: {0}\".format(sns.__version__),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0927c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So all output comes through from Ipython\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa4e5de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\run1\\OneDrive - CDC\\Learning Python\n"
     ]
    }
   ],
   "source": [
    "# Working Directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8bb436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set New Working Directory \n",
    "# the try except tells Python to try to run the code\n",
    "# and if an error occurs, print a message\n",
    "#try:\n",
    "os.chdir(r\"C:\\Users\\run1\\OneDrive - CDC\\IQVIA on My Disk\")\n",
    "#except:\n",
    " #   print(\"ERROR: You probably forgot to change the directory path!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d2f7fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My working directory:\n",
      "C:\\Users\\run1\\OneDrive - CDC\\IQVIA on My Disk\n"
     ]
    }
   ],
   "source": [
    "print(\"My working directory:\\n\" + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0650d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata(\"Full_working_matched_cleaned_non-preg_chronic_25March22Cut_2018.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e173ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['obese','Cancer', 'Congenital_mal_n', 'Congenital_mal_c','Congenital_mal_m', 'Sickle_cell', 'Congenital_HD',\n",
    "       'Esophageal_atresia', 'EoE', 'Seizure', 'Brain_injury','Slow_fetal_growth', 'Technology_dep', 'Gastro_eso_reflux',\n",
    "       'Lactose_int', 'Milk_protein_int', 'Malabs', 'Pancreatic_ins','Cirrhosis', 'Renal_tub', 'Diabetes_ins', 'Chronic_ren_ins',\n",
    "       'Kartagener_syn', 'Hypothyroidism', 'Adrenal_ins','Growth_horm_def', 'Inborn_err_met', 'Phenylketonuria','Maple_syr_urine_dis', 'Fructose_int', 'Gauchers_dis',\n",
    "       'Urea_cyc_dis', 'Fetal_alc_syn', 'Hyper_Ige_syn','Common_var_imm_def', \n",
    "       'inpatient_visit', 'total_inpatient_visit', 'agedays', \n",
    "       'gender','patient_state','oop_positive_exp', 'agecat1', 'agecat2','agecat3', 'agecat4', 'ethnicity_cat1', 'ethnicity_cat2',\n",
    "       'ethnicity_cat3', 'ethnicity_cat4', 'ethnicity_cat5','ethnicity_cat6', 'payert_cat1', 'payert_cat2', 'payert_cat3',\n",
    "       'region_cat1', 'region_cat2', 'region_cat3', 'region_cat4','region_cat5', 'total_inpatient_cost', 'total_outpatient_cost','oop_inpatient_cost', 'oop_outpatient_cost']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d976551",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obese</th>\n",
       "      <th>Cancer</th>\n",
       "      <th>Congenital_mal_n</th>\n",
       "      <th>Congenital_mal_c</th>\n",
       "      <th>Congenital_mal_m</th>\n",
       "      <th>Sickle_cell</th>\n",
       "      <th>Congenital_HD</th>\n",
       "      <th>Esophageal_atresia</th>\n",
       "      <th>EoE</th>\n",
       "      <th>Seizure</th>\n",
       "      <th>Brain_injury</th>\n",
       "      <th>Slow_fetal_growth</th>\n",
       "      <th>Technology_dep</th>\n",
       "      <th>Gastro_eso_reflux</th>\n",
       "      <th>Lactose_int</th>\n",
       "      <th>Milk_protein_int</th>\n",
       "      <th>Malabs</th>\n",
       "      <th>Pancreatic_ins</th>\n",
       "      <th>Cirrhosis</th>\n",
       "      <th>Renal_tub</th>\n",
       "      <th>Diabetes_ins</th>\n",
       "      <th>Chronic_ren_ins</th>\n",
       "      <th>Kartagener_syn</th>\n",
       "      <th>Hypothyroidism</th>\n",
       "      <th>Adrenal_ins</th>\n",
       "      <th>Growth_horm_def</th>\n",
       "      <th>Inborn_err_met</th>\n",
       "      <th>Phenylketonuria</th>\n",
       "      <th>Maple_syr_urine_dis</th>\n",
       "      <th>Fructose_int</th>\n",
       "      <th>Gauchers_dis</th>\n",
       "      <th>Urea_cyc_dis</th>\n",
       "      <th>Fetal_alc_syn</th>\n",
       "      <th>Hyper_Ige_syn</th>\n",
       "      <th>Common_var_imm_def</th>\n",
       "      <th>inpatient_visit</th>\n",
       "      <th>total_inpatient_visit</th>\n",
       "      <th>agedays</th>\n",
       "      <th>gender</th>\n",
       "      <th>patient_state</th>\n",
       "      <th>oop_positive_exp</th>\n",
       "      <th>agecat1</th>\n",
       "      <th>agecat2</th>\n",
       "      <th>agecat3</th>\n",
       "      <th>agecat4</th>\n",
       "      <th>ethnicity_cat1</th>\n",
       "      <th>ethnicity_cat2</th>\n",
       "      <th>ethnicity_cat3</th>\n",
       "      <th>ethnicity_cat4</th>\n",
       "      <th>ethnicity_cat5</th>\n",
       "      <th>ethnicity_cat6</th>\n",
       "      <th>payert_cat1</th>\n",
       "      <th>payert_cat2</th>\n",
       "      <th>payert_cat3</th>\n",
       "      <th>region_cat1</th>\n",
       "      <th>region_cat2</th>\n",
       "      <th>region_cat3</th>\n",
       "      <th>region_cat4</th>\n",
       "      <th>region_cat5</th>\n",
       "      <th>total_inpatient_cost</th>\n",
       "      <th>total_outpatient_cost</th>\n",
       "      <th>oop_inpatient_cost</th>\n",
       "      <th>oop_outpatient_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4923</td>\n",
       "      <td>Female</td>\n",
       "      <td>FL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.320000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1914</td>\n",
       "      <td>Female</td>\n",
       "      <td>IL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>730.290010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.650005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6233</td>\n",
       "      <td>Male</td>\n",
       "      <td>TN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1188.730002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>642.979987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5636</td>\n",
       "      <td>Male</td>\n",
       "      <td>FL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16445.579994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2491.529915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5145</td>\n",
       "      <td>Male</td>\n",
       "      <td>NC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>415.149997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159.780001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205871</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4930</td>\n",
       "      <td>Female</td>\n",
       "      <td>MN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4909.750080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1212.949993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205872</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7031</td>\n",
       "      <td>Female</td>\n",
       "      <td>KY</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2771.520005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1852.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205873</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>772</td>\n",
       "      <td>Male</td>\n",
       "      <td>FL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1779.329996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264.089996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205874</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7033</td>\n",
       "      <td>Female</td>\n",
       "      <td>IN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20125.609992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2105.559931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205875</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6044</td>\n",
       "      <td>Female</td>\n",
       "      <td>TN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1138.980004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>570.880003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205876 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        obese  Cancer  Congenital_mal_n  Congenital_mal_c  Congenital_mal_m  Sickle_cell  Congenital_HD  Esophageal_atresia  EoE  Seizure  Brain_injury  Slow_fetal_growth  Technology_dep  Gastro_eso_reflux  Lactose_int  Milk_protein_int  Malabs  Pancreatic_ins  Cirrhosis  Renal_tub  Diabetes_ins  Chronic_ren_ins  Kartagener_syn  Hypothyroidism  Adrenal_ins  Growth_horm_def  Inborn_err_met  Phenylketonuria  Maple_syr_urine_dis  Fructose_int  Gauchers_dis  Urea_cyc_dis  Fetal_alc_syn  Hyper_Ige_syn  Common_var_imm_def  inpatient_visit  total_inpatient_visit  agedays  gender patient_state  oop_positive_exp  agecat1  agecat2  agecat3  agecat4  ethnicity_cat1  ethnicity_cat2  ethnicity_cat3  ethnicity_cat4  ethnicity_cat5  ethnicity_cat6  payert_cat1  payert_cat2  payert_cat3  region_cat1  region_cat2  region_cat3  region_cat4  region_cat5  total_inpatient_cost  total_outpatient_cost  oop_inpatient_cost  oop_outpatient_cost\n",
       "0           0     0.0               0.0               0.0               0.0          0.0            0.0                 0.0  0.0      0.0           0.0                0.0             0.0                0.0          0.0               0.0     0.0             0.0        0.0        0.0           0.0              0.0             0.0             0.0          0.0              0.0             0.0              0.0                  0.0           0.0           0.0           0.0            0.0            0.0                 0.0              0.0                    0.0     4923  Female            FL               1.0        0        0        1        0               0               0               1               0               0               0            1            0            0          0.0          0.0          0.0          1.0          0.0                   0.0              91.320000                 0.0            91.320000\n",
       "1           0     0.0               0.0               0.0               0.0          0.0            0.0                 0.0  0.0      0.0           0.0                0.0             0.0                0.0          0.0               0.0     0.0             0.0        0.0        0.0           0.0              0.0             0.0             0.0          0.0              0.0             0.0              0.0                  0.0           0.0           0.0           0.0            0.0            0.0                 0.0              0.0                    0.0     1914  Female            IL               1.0        1        0        0        0               0               0               0               0               0               1            0            0            1          0.0          1.0          0.0          0.0          0.0                   0.0             730.290010                 0.0            93.650005\n",
       "2           1     0.0               0.0               0.0               0.0          0.0            0.0                 0.0  0.0      0.0           0.0                0.0             0.0                0.0          0.0               0.0     0.0             0.0        0.0        0.0           0.0              0.0             0.0             0.0          0.0              0.0             0.0              0.0                  0.0           0.0           0.0           0.0            0.0            0.0                 0.0              0.0                    0.0     6233    Male            TN               1.0        0        0        1        0               0               0               0               0               0               1            1            0            0          0.0          0.0          0.0          1.0          0.0                   0.0            1188.730002                 0.0           642.979987\n",
       "3           1     0.0               0.0               0.0               0.0          0.0            0.0                 0.0  0.0      0.0           0.0                0.0             0.0                0.0          0.0               0.0     0.0             0.0        0.0        0.0           0.0              0.0             0.0             0.0          0.0              0.0             0.0              0.0                  0.0           0.0           0.0           0.0            0.0            0.0                 0.0              0.0                    0.0     5636    Male            FL               1.0        0        0        1        0               1               0               0               0               0               0            0            1            0          0.0          0.0          0.0          1.0          0.0                   0.0           16445.579994                 0.0          2491.529915\n",
       "4           1     0.0               0.0               0.0               0.0          0.0            0.0                 0.0  0.0      0.0           0.0                0.0             0.0                0.0          0.0               0.0     0.0             0.0        0.0        0.0           0.0              0.0             0.0             0.0          0.0              0.0             0.0              0.0                  0.0           0.0           0.0           0.0            0.0            0.0                 0.0              0.0                    0.0     5145    Male            NC               1.0        0        0        1        0               0               0               1               0               0               0            0            0            1          0.0          0.0          0.0          1.0          0.0                   0.0             415.149997                 0.0           159.780001\n",
       "...       ...     ...               ...               ...               ...          ...            ...                 ...  ...      ...           ...                ...             ...                ...          ...               ...     ...             ...        ...        ...           ...              ...             ...             ...          ...              ...             ...              ...                  ...           ...           ...           ...            ...            ...                 ...              ...                    ...      ...     ...           ...               ...      ...      ...      ...      ...             ...             ...             ...             ...             ...             ...          ...          ...          ...          ...          ...          ...          ...          ...                   ...                    ...                 ...                  ...\n",
       "205871      0     0.0               0.0               0.0               0.0          0.0            0.0                 0.0  0.0      0.0           0.0                0.0             0.0                0.0          0.0               0.0     0.0             0.0        0.0        0.0           0.0              0.0             0.0             0.0          0.0              0.0             0.0              0.0                  0.0           0.0           0.0           0.0            0.0            0.0                 0.0              0.0                    0.0     4930  Female            MN               1.0        0        0        1        0               0               0               1               0               0               0            0            0            1          0.0          1.0          0.0          0.0          0.0                   0.0            4909.750080                 0.0          1212.949993\n",
       "205872      0     0.0               0.0               0.0               0.0          0.0            0.0                 0.0  0.0      0.0           0.0                0.0             0.0                0.0          0.0               0.0     0.0             0.0        0.0        0.0           0.0              0.0             0.0             0.0          0.0              0.0             0.0              0.0                  0.0           0.0           0.0           0.0            0.0            0.0                 0.0              0.0                    0.0     7031  Female            KY               1.0        0        0        0        1               0               0               1               0               0               0            1            0            0          0.0          0.0          0.0          1.0          0.0                   0.0            2771.520005                 0.0          1852.400000\n",
       "205873      0     0.0               0.0               0.0               0.0          0.0            0.0                 0.0  0.0      0.0           0.0                0.0             0.0                0.0          0.0               0.0     0.0             0.0        0.0        0.0           0.0              0.0             0.0             0.0          0.0              0.0             0.0              0.0                  0.0           0.0           0.0           0.0            0.0            0.0                 0.0              0.0                    0.0      772    Male            FL               1.0        1        0        0        0               0               1               0               0               0               0            1            0            0          0.0          0.0          0.0          1.0          0.0                   0.0            1779.329996                 0.0           264.089996\n",
       "205874      0     0.0               0.0               0.0               0.0          0.0            0.0                 0.0  0.0      0.0           1.0                0.0             0.0                0.0          0.0               0.0     0.0             0.0        0.0        0.0           0.0              0.0             0.0             0.0          0.0              0.0             0.0              0.0                  0.0           0.0           0.0           0.0            0.0            0.0                 0.0              0.0                    0.0     7033  Female            IN               1.0        0        0        0        1               0               0               1               0               0               0            0            0            1          0.0          1.0          0.0          0.0          0.0                   0.0           20125.609992                 0.0          2105.559931\n",
       "205875      0     0.0               0.0               0.0               0.0          0.0            0.0                 0.0  0.0      0.0           0.0                0.0             0.0                0.0          0.0               0.0     0.0             0.0        0.0        0.0           0.0              0.0             0.0             0.0          0.0              0.0             0.0              0.0                  0.0           0.0           0.0           0.0            0.0            0.0                 0.0              0.0                    0.0     6044  Female            TN               1.0        0        0        1        0               0               0               0               0               0               1            0            0            1          0.0          0.0          0.0          1.0          0.0                   0.0            1138.980004                 0.0           570.880003\n",
       "\n",
       "[205876 rows x 63 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context(\"display.max_columns\", None):\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60016b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 205876 entries, 0 to 205875\n",
      "Data columns (total 63 columns):\n",
      " #   Column                 Non-Null Count   Dtype   \n",
      "---  ------                 --------------   -----   \n",
      " 0   obese                  205876 non-null  int8    \n",
      " 1   Cancer                 205876 non-null  float64 \n",
      " 2   Congenital_mal_n       205876 non-null  float64 \n",
      " 3   Congenital_mal_c       205876 non-null  float64 \n",
      " 4   Congenital_mal_m       205876 non-null  float64 \n",
      " 5   Sickle_cell            205876 non-null  float64 \n",
      " 6   Congenital_HD          205876 non-null  float64 \n",
      " 7   Esophageal_atresia     205876 non-null  float64 \n",
      " 8   EoE                    205876 non-null  float64 \n",
      " 9   Seizure                205876 non-null  float64 \n",
      " 10  Brain_injury           205876 non-null  float64 \n",
      " 11  Slow_fetal_growth      205876 non-null  float64 \n",
      " 12  Technology_dep         205876 non-null  float64 \n",
      " 13  Gastro_eso_reflux      205876 non-null  float64 \n",
      " 14  Lactose_int            205876 non-null  float64 \n",
      " 15  Milk_protein_int       205876 non-null  float64 \n",
      " 16  Malabs                 205876 non-null  float64 \n",
      " 17  Pancreatic_ins         205876 non-null  float64 \n",
      " 18  Cirrhosis              205876 non-null  float64 \n",
      " 19  Renal_tub              205876 non-null  float64 \n",
      " 20  Diabetes_ins           205876 non-null  float64 \n",
      " 21  Chronic_ren_ins        205876 non-null  float64 \n",
      " 22  Kartagener_syn         205876 non-null  float64 \n",
      " 23  Hypothyroidism         205876 non-null  float64 \n",
      " 24  Adrenal_ins            205876 non-null  float64 \n",
      " 25  Growth_horm_def        205876 non-null  float64 \n",
      " 26  Inborn_err_met         205876 non-null  float64 \n",
      " 27  Phenylketonuria        205876 non-null  float64 \n",
      " 28  Maple_syr_urine_dis    205876 non-null  float64 \n",
      " 29  Fructose_int           205876 non-null  float64 \n",
      " 30  Gauchers_dis           205876 non-null  float64 \n",
      " 31  Urea_cyc_dis           205876 non-null  float64 \n",
      " 32  Fetal_alc_syn          205876 non-null  float64 \n",
      " 33  Hyper_Ige_syn          205876 non-null  float64 \n",
      " 34  Common_var_imm_def     205876 non-null  float64 \n",
      " 35  inpatient_visit        205876 non-null  float32 \n",
      " 36  total_inpatient_visit  205876 non-null  float32 \n",
      " 37  agedays                205876 non-null  int16   \n",
      " 38  gender                 205876 non-null  category\n",
      " 39  patient_state          205824 non-null  category\n",
      " 40  oop_positive_exp       205876 non-null  float32 \n",
      " 41  agecat1                205876 non-null  int8    \n",
      " 42  agecat2                205876 non-null  int8    \n",
      " 43  agecat3                205876 non-null  int8    \n",
      " 44  agecat4                205876 non-null  int8    \n",
      " 45  ethnicity_cat1         205876 non-null  int8    \n",
      " 46  ethnicity_cat2         205876 non-null  int8    \n",
      " 47  ethnicity_cat3         205876 non-null  int8    \n",
      " 48  ethnicity_cat4         205876 non-null  int8    \n",
      " 49  ethnicity_cat5         205876 non-null  int8    \n",
      " 50  ethnicity_cat6         205876 non-null  int8    \n",
      " 51  payert_cat1            205876 non-null  int8    \n",
      " 52  payert_cat2            205876 non-null  int8    \n",
      " 53  payert_cat3            205876 non-null  int8    \n",
      " 54  region_cat1            205826 non-null  float64 \n",
      " 55  region_cat2            205826 non-null  float64 \n",
      " 56  region_cat3            205826 non-null  float64 \n",
      " 57  region_cat4            205826 non-null  float64 \n",
      " 58  region_cat5            205826 non-null  float64 \n",
      " 59  total_inpatient_cost   205876 non-null  float64 \n",
      " 60  total_outpatient_cost  205876 non-null  float64 \n",
      " 61  oop_inpatient_cost     205876 non-null  float64 \n",
      " 62  oop_outpatient_cost    205876 non-null  float64 \n",
      "dtypes: category(2), float32(3), float64(43), int16(1), int8(14)\n",
      "memory usage: 75.0 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obese</th>\n",
       "      <th>Cancer</th>\n",
       "      <th>Congenital_mal_n</th>\n",
       "      <th>Congenital_mal_c</th>\n",
       "      <th>Congenital_mal_m</th>\n",
       "      <th>Sickle_cell</th>\n",
       "      <th>Congenital_HD</th>\n",
       "      <th>Esophageal_atresia</th>\n",
       "      <th>EoE</th>\n",
       "      <th>Seizure</th>\n",
       "      <th>Brain_injury</th>\n",
       "      <th>Slow_fetal_growth</th>\n",
       "      <th>Technology_dep</th>\n",
       "      <th>Gastro_eso_reflux</th>\n",
       "      <th>Lactose_int</th>\n",
       "      <th>Milk_protein_int</th>\n",
       "      <th>Malabs</th>\n",
       "      <th>Pancreatic_ins</th>\n",
       "      <th>Cirrhosis</th>\n",
       "      <th>Renal_tub</th>\n",
       "      <th>Diabetes_ins</th>\n",
       "      <th>Chronic_ren_ins</th>\n",
       "      <th>Kartagener_syn</th>\n",
       "      <th>Hypothyroidism</th>\n",
       "      <th>Adrenal_ins</th>\n",
       "      <th>Growth_horm_def</th>\n",
       "      <th>Inborn_err_met</th>\n",
       "      <th>Phenylketonuria</th>\n",
       "      <th>Maple_syr_urine_dis</th>\n",
       "      <th>Fructose_int</th>\n",
       "      <th>Gauchers_dis</th>\n",
       "      <th>Urea_cyc_dis</th>\n",
       "      <th>Fetal_alc_syn</th>\n",
       "      <th>Hyper_Ige_syn</th>\n",
       "      <th>Common_var_imm_def</th>\n",
       "      <th>inpatient_visit</th>\n",
       "      <th>total_inpatient_visit</th>\n",
       "      <th>agedays</th>\n",
       "      <th>oop_positive_exp</th>\n",
       "      <th>agecat1</th>\n",
       "      <th>agecat2</th>\n",
       "      <th>agecat3</th>\n",
       "      <th>agecat4</th>\n",
       "      <th>ethnicity_cat1</th>\n",
       "      <th>ethnicity_cat2</th>\n",
       "      <th>ethnicity_cat3</th>\n",
       "      <th>ethnicity_cat4</th>\n",
       "      <th>ethnicity_cat5</th>\n",
       "      <th>ethnicity_cat6</th>\n",
       "      <th>payert_cat1</th>\n",
       "      <th>payert_cat2</th>\n",
       "      <th>payert_cat3</th>\n",
       "      <th>region_cat1</th>\n",
       "      <th>region_cat2</th>\n",
       "      <th>region_cat3</th>\n",
       "      <th>region_cat4</th>\n",
       "      <th>region_cat5</th>\n",
       "      <th>total_inpatient_cost</th>\n",
       "      <th>total_outpatient_cost</th>\n",
       "      <th>oop_inpatient_cost</th>\n",
       "      <th>oop_outpatient_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.00000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.00000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205826.000000</td>\n",
       "      <td>205826.000000</td>\n",
       "      <td>205826.000000</td>\n",
       "      <td>205826.000000</td>\n",
       "      <td>205826.000000</td>\n",
       "      <td>2.058760e+05</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "      <td>205876.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.155773</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.004658</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>0.005387</td>\n",
       "      <td>0.015446</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.017953</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.00016</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.006577</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00016</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.019939</td>\n",
       "      <td>0.026739</td>\n",
       "      <td>4230.571509</td>\n",
       "      <td>0.885052</td>\n",
       "      <td>0.193617</td>\n",
       "      <td>0.306306</td>\n",
       "      <td>0.361800</td>\n",
       "      <td>0.138277</td>\n",
       "      <td>0.054951</td>\n",
       "      <td>0.025190</td>\n",
       "      <td>0.688303</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>0.022169</td>\n",
       "      <td>0.204050</td>\n",
       "      <td>0.349312</td>\n",
       "      <td>0.082827</td>\n",
       "      <td>0.567861</td>\n",
       "      <td>0.150938</td>\n",
       "      <td>0.344208</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.421366</td>\n",
       "      <td>0.083478</td>\n",
       "      <td>6.625742e+02</td>\n",
       "      <td>2480.736079</td>\n",
       "      <td>45.415488</td>\n",
       "      <td>587.837128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.362641</td>\n",
       "      <td>0.042241</td>\n",
       "      <td>0.047726</td>\n",
       "      <td>0.068092</td>\n",
       "      <td>0.035378</td>\n",
       "      <td>0.017490</td>\n",
       "      <td>0.020904</td>\n",
       "      <td>0.008246</td>\n",
       "      <td>0.043539</td>\n",
       "      <td>0.073197</td>\n",
       "      <td>0.123319</td>\n",
       "      <td>0.006234</td>\n",
       "      <td>0.044744</td>\n",
       "      <td>0.132779</td>\n",
       "      <td>0.031463</td>\n",
       "      <td>0.036457</td>\n",
       "      <td>0.052912</td>\n",
       "      <td>0.021701</td>\n",
       "      <td>0.010337</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.01266</td>\n",
       "      <td>0.011661</td>\n",
       "      <td>0.007309</td>\n",
       "      <td>0.080830</td>\n",
       "      <td>0.018827</td>\n",
       "      <td>0.051711</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>0.01266</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>0.002204</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.014451</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>0.014451</td>\n",
       "      <td>0.139930</td>\n",
       "      <td>0.237600</td>\n",
       "      <td>1903.691404</td>\n",
       "      <td>0.319311</td>\n",
       "      <td>0.395133</td>\n",
       "      <td>0.460959</td>\n",
       "      <td>0.480523</td>\n",
       "      <td>0.345192</td>\n",
       "      <td>0.227884</td>\n",
       "      <td>0.156702</td>\n",
       "      <td>0.463188</td>\n",
       "      <td>0.072868</td>\n",
       "      <td>0.147232</td>\n",
       "      <td>0.403007</td>\n",
       "      <td>0.476754</td>\n",
       "      <td>0.275621</td>\n",
       "      <td>0.495375</td>\n",
       "      <td>0.357989</td>\n",
       "      <td>0.475111</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>0.493779</td>\n",
       "      <td>0.276604</td>\n",
       "      <td>1.149449e+04</td>\n",
       "      <td>6992.525004</td>\n",
       "      <td>1342.915030</td>\n",
       "      <td>1426.562868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>731.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-34708.279224</td>\n",
       "      <td>-5219.890446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2618.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>401.740001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4383.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>854.115000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>199.945003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5858.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2121.352502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>640.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>7304.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.901839e+06</td>\n",
       "      <td>667090.227844</td>\n",
       "      <td>336561.997265</td>\n",
       "      <td>309166.730882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               obese         Cancer  Congenital_mal_n  Congenital_mal_c  Congenital_mal_m    Sickle_cell  Congenital_HD  Esophageal_atresia            EoE        Seizure   Brain_injury  Slow_fetal_growth  Technology_dep  Gastro_eso_reflux    Lactose_int  Milk_protein_int         Malabs  Pancreatic_ins      Cirrhosis      Renal_tub  Diabetes_ins  Chronic_ren_ins  Kartagener_syn  Hypothyroidism    Adrenal_ins  Growth_horm_def  Inborn_err_met  Phenylketonuria  Maple_syr_urine_dis   Fructose_int   Gauchers_dis   Urea_cyc_dis  Fetal_alc_syn  Hyper_Ige_syn  Common_var_imm_def  inpatient_visit  total_inpatient_visit        agedays  oop_positive_exp        agecat1        agecat2        agecat3        agecat4  ethnicity_cat1  ethnicity_cat2  ethnicity_cat3  ethnicity_cat4  ethnicity_cat5  ethnicity_cat6    payert_cat1    payert_cat2    payert_cat3    region_cat1    region_cat2    region_cat3    region_cat4    region_cat5  total_inpatient_cost  total_outpatient_cost  oop_inpatient_cost  \\\n",
       "count  205876.000000  205876.000000     205876.000000     205876.000000     205876.000000  205876.000000  205876.000000       205876.000000  205876.000000  205876.000000  205876.000000      205876.000000   205876.000000      205876.000000  205876.000000     205876.000000  205876.000000   205876.000000  205876.000000  205876.000000  205876.00000    205876.000000   205876.000000   205876.000000  205876.000000    205876.000000   205876.000000     205876.00000        205876.000000  205876.000000  205876.000000  205876.000000  205876.000000  205876.000000       205876.000000    205876.000000          205876.000000  205876.000000     205876.000000  205876.000000  205876.000000  205876.000000  205876.000000   205876.000000   205876.000000   205876.000000   205876.000000   205876.000000   205876.000000  205876.000000  205876.000000  205876.000000  205826.000000  205826.000000  205826.000000  205826.000000  205826.000000          2.058760e+05          205876.000000       205876.000000   \n",
       "mean        0.155773       0.001787          0.002283          0.004658          0.001253       0.000306       0.000437            0.000068       0.001899       0.005387       0.015446           0.000039        0.002006           0.017953       0.000991          0.001331       0.002808        0.000471       0.000107       0.000049       0.00016         0.000136        0.000053        0.006577       0.000355         0.002681        0.000015          0.00016             0.000015       0.000005       0.000010       0.000049       0.000209       0.000015            0.000209         0.019939               0.026739    4230.571509          0.885052       0.193617       0.306306       0.361800       0.138277        0.054951        0.025190        0.688303        0.005338        0.022169        0.204050       0.349312       0.082827       0.567861       0.150938       0.344208       0.000010       0.421366       0.083478          6.625742e+02            2480.736079           45.415488   \n",
       "std         0.362641       0.042241          0.047726          0.068092          0.035378       0.017490       0.020904            0.008246       0.043539       0.073197       0.123319           0.006234        0.044744           0.132779       0.031463          0.036457       0.052912        0.021701       0.010337       0.006969       0.01266         0.011661        0.007309        0.080830       0.018827         0.051711        0.003817          0.01266             0.003817       0.002204       0.003117       0.006969       0.014451       0.003817            0.014451         0.139930               0.237600    1903.691404          0.319311       0.395133       0.460959       0.480523       0.345192        0.227884        0.156702        0.463188        0.072868        0.147232        0.403007       0.476754       0.275621       0.495375       0.357989       0.475111       0.003117       0.493779       0.276604          1.149449e+04            6992.525004         1342.915030   \n",
       "min         0.000000       0.000000          0.000000          0.000000          0.000000       0.000000       0.000000            0.000000       0.000000       0.000000       0.000000           0.000000        0.000000           0.000000       0.000000          0.000000       0.000000        0.000000       0.000000       0.000000       0.00000         0.000000        0.000000        0.000000       0.000000         0.000000        0.000000          0.00000             0.000000       0.000000       0.000000       0.000000       0.000000       0.000000            0.000000         0.000000               0.000000     731.000000          0.000000       0.000000       0.000000       0.000000       0.000000        0.000000        0.000000        0.000000        0.000000        0.000000        0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000          0.000000e+00               0.000000       -34708.279224   \n",
       "25%         0.000000       0.000000          0.000000          0.000000          0.000000       0.000000       0.000000            0.000000       0.000000       0.000000       0.000000           0.000000        0.000000           0.000000       0.000000          0.000000       0.000000        0.000000       0.000000       0.000000       0.00000         0.000000        0.000000        0.000000       0.000000         0.000000        0.000000          0.00000             0.000000       0.000000       0.000000       0.000000       0.000000       0.000000            0.000000         0.000000               0.000000    2618.000000          1.000000       0.000000       0.000000       0.000000       0.000000        0.000000        0.000000        0.000000        0.000000        0.000000        0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000       0.000000          0.000000e+00             401.740001            0.000000   \n",
       "50%         0.000000       0.000000          0.000000          0.000000          0.000000       0.000000       0.000000            0.000000       0.000000       0.000000       0.000000           0.000000        0.000000           0.000000       0.000000          0.000000       0.000000        0.000000       0.000000       0.000000       0.00000         0.000000        0.000000        0.000000       0.000000         0.000000        0.000000          0.00000             0.000000       0.000000       0.000000       0.000000       0.000000       0.000000            0.000000         0.000000               0.000000    4383.000000          1.000000       0.000000       0.000000       0.000000       0.000000        0.000000        0.000000        1.000000        0.000000        0.000000        0.000000       0.000000       0.000000       1.000000       0.000000       0.000000       0.000000       0.000000       0.000000          0.000000e+00             854.115000            0.000000   \n",
       "75%         0.000000       0.000000          0.000000          0.000000          0.000000       0.000000       0.000000            0.000000       0.000000       0.000000       0.000000           0.000000        0.000000           0.000000       0.000000          0.000000       0.000000        0.000000       0.000000       0.000000       0.00000         0.000000        0.000000        0.000000       0.000000         0.000000        0.000000          0.00000             0.000000       0.000000       0.000000       0.000000       0.000000       0.000000            0.000000         0.000000               0.000000    5858.000000          1.000000       0.000000       1.000000       1.000000       0.000000        0.000000        0.000000        1.000000        0.000000        0.000000        0.000000       1.000000       0.000000       1.000000       0.000000       1.000000       0.000000       1.000000       0.000000          0.000000e+00            2121.352502            0.000000   \n",
       "max         1.000000       1.000000          1.000000          1.000000          1.000000       1.000000       1.000000            1.000000       1.000000       1.000000       1.000000           1.000000        1.000000           1.000000       1.000000          1.000000       1.000000        1.000000       1.000000       1.000000       1.00000         1.000000        1.000000        1.000000       1.000000         1.000000        1.000000          1.00000             1.000000       1.000000       1.000000       1.000000       1.000000       1.000000            1.000000         1.000000              22.000000    7304.000000          1.000000       1.000000       1.000000       1.000000       1.000000        1.000000        1.000000        1.000000        1.000000        1.000000        1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000       1.000000          1.901839e+06          667090.227844       336561.997265   \n",
       "\n",
       "       oop_outpatient_cost  \n",
       "count        205876.000000  \n",
       "mean            587.837128  \n",
       "std            1426.562868  \n",
       "min           -5219.890446  \n",
       "25%              50.000000  \n",
       "50%             199.945003  \n",
       "75%             640.000024  \n",
       "max          309166.730882  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a27f5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'obese ~ Fructose_int+ Cancer+ Milk_protein_int+ Common_var_imm_def+ agecat4+ ethnicity_cat6+ Congenital_mal_m+ Pancreatic_ins+ ethnicity_cat2+ Gauchers_dis+ Adrenal_ins+ Lactose_int+ Inborn_err_met+ total_outpatient_cost+ Congenital_HD+ Cirrhosis+ Chronic_ren_ins+ Malabs+ Urea_cyc_dis+ Technology_dep+ inpatient_visit+ Phenylketonuria+ EoE+ agedays+ region_cat5+ oop_inpatient_cost+ oop_outpatient_cost+ ethnicity_cat5+ Esophageal_atresia+ Congenital_mal_n+ ethnicity_cat4+ Maple_syr_urine_dis+ ethnicity_cat1+ Diabetes_ins+ payert_cat1+ Slow_fetal_growth+ Fetal_alc_syn+ total_inpatient_visit+ agecat1+ ethnicity_cat3+ patient_state+ oop_positive_exp+ agecat2+ Hyper_Ige_syn+ region_cat3+ Congenital_mal_c+ Sickle_cell+ agecat3+ region_cat4+ Kartagener_syn+ payert_cat3+ Brain_injury+ Renal_tub+ Seizure+ region_cat2+ total_inpatient_cost+ Gastro_eso_reflux+ payert_cat2+ Hypothyroidism+ region_cat1+ gender+ Growth_horm_def'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create formula for all variables in the model\n",
    "vars_remove= ['obese']\n",
    "vars_left = set(df.columns) - set(vars_remove)\n",
    "formula = \"obese ~ \" + \"+ \".join(vars_left)\n",
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5e8579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use Patsy to create model matrices\n",
    "from patsy import dmatrices\n",
    "Y, X = dmatrices(formula, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df9075d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DesignMatrix with shape (205824, 1)\n",
       "  obese\n",
       "      0\n",
       "      0\n",
       "      1\n",
       "      1\n",
       "      1\n",
       "      0\n",
       "      0\n",
       "      0\n",
       "      0\n",
       "      0\n",
       "      0\n",
       "      0\n",
       "      0\n",
       "      0\n",
       "      0\n",
       "      0\n",
       "      0\n",
       "      1\n",
       "      0\n",
       "      1\n",
       "      0\n",
       "      0\n",
       "      0\n",
       "      0\n",
       "      0\n",
       "      1\n",
       "      0\n",
       "      0\n",
       "      0\n",
       "      0\n",
       "  [205794 rows omitted]\n",
       "  Terms:\n",
       "    'obese' (column 0)\n",
       "  (to view full data, use np.asarray(this_obj))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DesignMatrix with shape (205824, 112)\n",
       "  Columns:\n",
       "    ['Intercept',\n",
       "     'patient_state[T.AL]',\n",
       "     'patient_state[T.AR]',\n",
       "     'patient_state[T.AZ]',\n",
       "     'patient_state[T.CA]',\n",
       "     'patient_state[T.CO]',\n",
       "     'patient_state[T.CT]',\n",
       "     'patient_state[T.DC]',\n",
       "     'patient_state[T.DE]',\n",
       "     'patient_state[T.FL]',\n",
       "     'patient_state[T.GA]',\n",
       "     'patient_state[T.HI]',\n",
       "     'patient_state[T.IA]',\n",
       "     'patient_state[T.ID]',\n",
       "     'patient_state[T.IL]',\n",
       "     'patient_state[T.IN]',\n",
       "     'patient_state[T.KS]',\n",
       "     'patient_state[T.KY]',\n",
       "     'patient_state[T.LA]',\n",
       "     'patient_state[T.MA]',\n",
       "     'patient_state[T.MD]',\n",
       "     'patient_state[T.ME]',\n",
       "     'patient_state[T.MI]',\n",
       "     'patient_state[T.MN]',\n",
       "     'patient_state[T.MO]',\n",
       "     'patient_state[T.MS]',\n",
       "     'patient_state[T.MT]',\n",
       "     'patient_state[T.NC]',\n",
       "     'patient_state[T.ND]',\n",
       "     'patient_state[T.NE]',\n",
       "     'patient_state[T.NH]',\n",
       "     'patient_state[T.NJ]',\n",
       "     'patient_state[T.NM]',\n",
       "     'patient_state[T.NV]',\n",
       "     'patient_state[T.NY]',\n",
       "     'patient_state[T.OH]',\n",
       "     'patient_state[T.OK]',\n",
       "     'patient_state[T.OR]',\n",
       "     'patient_state[T.PA]',\n",
       "     'patient_state[T.RI]',\n",
       "     'patient_state[T.SC]',\n",
       "     'patient_state[T.SD]',\n",
       "     'patient_state[T.TN]',\n",
       "     'patient_state[T.TX]',\n",
       "     'patient_state[T.UT]',\n",
       "     'patient_state[T.VA]',\n",
       "     'patient_state[T.VT]',\n",
       "     'patient_state[T.WA]',\n",
       "     'patient_state[T.WI]',\n",
       "     'patient_state[T.WV]',\n",
       "     'patient_state[T.WY]',\n",
       "     'gender[T.Female]',\n",
       "     'Fructose_int',\n",
       "     'Cancer',\n",
       "     'Milk_protein_int',\n",
       "     'Common_var_imm_def',\n",
       "     'agecat4',\n",
       "     'ethnicity_cat6',\n",
       "     'Congenital_mal_m',\n",
       "     'Pancreatic_ins',\n",
       "     'ethnicity_cat2',\n",
       "     'Gauchers_dis',\n",
       "     'Adrenal_ins',\n",
       "     'Lactose_int',\n",
       "     'Inborn_err_met',\n",
       "     'total_outpatient_cost',\n",
       "     'Congenital_HD',\n",
       "     'Cirrhosis',\n",
       "     'Chronic_ren_ins',\n",
       "     'Malabs',\n",
       "     'Urea_cyc_dis',\n",
       "     'Technology_dep',\n",
       "     'inpatient_visit',\n",
       "     'Phenylketonuria',\n",
       "     'EoE',\n",
       "     'agedays',\n",
       "     'region_cat5',\n",
       "     'oop_inpatient_cost',\n",
       "     'oop_outpatient_cost',\n",
       "     'ethnicity_cat5',\n",
       "     'Esophageal_atresia',\n",
       "     'Congenital_mal_n',\n",
       "     'ethnicity_cat4',\n",
       "     'Maple_syr_urine_dis',\n",
       "     'ethnicity_cat1',\n",
       "     'Diabetes_ins',\n",
       "     'payert_cat1',\n",
       "     'Slow_fetal_growth',\n",
       "     'Fetal_alc_syn',\n",
       "     'total_inpatient_visit',\n",
       "     'agecat1',\n",
       "     'ethnicity_cat3',\n",
       "     'oop_positive_exp',\n",
       "     'agecat2',\n",
       "     'Hyper_Ige_syn',\n",
       "     'region_cat3',\n",
       "     'Congenital_mal_c',\n",
       "     'Sickle_cell',\n",
       "     'agecat3',\n",
       "     'region_cat4',\n",
       "     'Kartagener_syn',\n",
       "     'payert_cat3',\n",
       "     'Brain_injury',\n",
       "     'Renal_tub',\n",
       "     'Seizure',\n",
       "     'region_cat2',\n",
       "     'total_inpatient_cost',\n",
       "     'Gastro_eso_reflux',\n",
       "     'payert_cat2',\n",
       "     'Hypothyroidism',\n",
       "     'region_cat1',\n",
       "     'Growth_horm_def']\n",
       "  Terms:\n",
       "    'Intercept' (column 0)\n",
       "    'patient_state' (columns 1:51)\n",
       "    'gender' (column 51)\n",
       "    'Fructose_int' (column 52)\n",
       "    'Cancer' (column 53)\n",
       "    'Milk_protein_int' (column 54)\n",
       "    'Common_var_imm_def' (column 55)\n",
       "    'agecat4' (column 56)\n",
       "    'ethnicity_cat6' (column 57)\n",
       "    'Congenital_mal_m' (column 58)\n",
       "    'Pancreatic_ins' (column 59)\n",
       "    'ethnicity_cat2' (column 60)\n",
       "    'Gauchers_dis' (column 61)\n",
       "    'Adrenal_ins' (column 62)\n",
       "    'Lactose_int' (column 63)\n",
       "    'Inborn_err_met' (column 64)\n",
       "    'total_outpatient_cost' (column 65)\n",
       "    'Congenital_HD' (column 66)\n",
       "    'Cirrhosis' (column 67)\n",
       "    'Chronic_ren_ins' (column 68)\n",
       "    'Malabs' (column 69)\n",
       "    'Urea_cyc_dis' (column 70)\n",
       "    'Technology_dep' (column 71)\n",
       "    'inpatient_visit' (column 72)\n",
       "    'Phenylketonuria' (column 73)\n",
       "    'EoE' (column 74)\n",
       "    'agedays' (column 75)\n",
       "    'region_cat5' (column 76)\n",
       "    'oop_inpatient_cost' (column 77)\n",
       "    'oop_outpatient_cost' (column 78)\n",
       "    'ethnicity_cat5' (column 79)\n",
       "    'Esophageal_atresia' (column 80)\n",
       "    'Congenital_mal_n' (column 81)\n",
       "    'ethnicity_cat4' (column 82)\n",
       "    'Maple_syr_urine_dis' (column 83)\n",
       "    'ethnicity_cat1' (column 84)\n",
       "    'Diabetes_ins' (column 85)\n",
       "    'payert_cat1' (column 86)\n",
       "    'Slow_fetal_growth' (column 87)\n",
       "    'Fetal_alc_syn' (column 88)\n",
       "    'total_inpatient_visit' (column 89)\n",
       "    'agecat1' (column 90)\n",
       "    'ethnicity_cat3' (column 91)\n",
       "    'oop_positive_exp' (column 92)\n",
       "    'agecat2' (column 93)\n",
       "    'Hyper_Ige_syn' (column 94)\n",
       "    'region_cat3' (column 95)\n",
       "    'Congenital_mal_c' (column 96)\n",
       "    'Sickle_cell' (column 97)\n",
       "    'agecat3' (column 98)\n",
       "    'region_cat4' (column 99)\n",
       "    'Kartagener_syn' (column 100)\n",
       "    'payert_cat3' (column 101)\n",
       "    'Brain_injury' (column 102)\n",
       "    'Renal_tub' (column 103)\n",
       "    'Seizure' (column 104)\n",
       "    'region_cat2' (column 105)\n",
       "    'total_inpatient_cost' (column 106)\n",
       "    'Gastro_eso_reflux' (column 107)\n",
       "    'payert_cat2' (column 108)\n",
       "    'Hypothyroidism' (column 109)\n",
       "    'region_cat1' (column 110)\n",
       "    'Growth_horm_def' (column 111)\n",
       "  (to view full data, use np.asarray(this_obj))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "90b30844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DesignMatrix with shape (205824, 112)\n",
       "  Columns:\n",
       "    ['Intercept',\n",
       "     'patient_state[T.AL]',\n",
       "     'patient_state[T.AR]',\n",
       "     'patient_state[T.AZ]',\n",
       "     'patient_state[T.CA]',\n",
       "     'patient_state[T.CO]',\n",
       "     'patient_state[T.CT]',\n",
       "     'patient_state[T.DC]',\n",
       "     'patient_state[T.DE]',\n",
       "     'patient_state[T.FL]',\n",
       "     'patient_state[T.GA]',\n",
       "     'patient_state[T.HI]',\n",
       "     'patient_state[T.IA]',\n",
       "     'patient_state[T.ID]',\n",
       "     'patient_state[T.IL]',\n",
       "     'patient_state[T.IN]',\n",
       "     'patient_state[T.KS]',\n",
       "     'patient_state[T.KY]',\n",
       "     'patient_state[T.LA]',\n",
       "     'patient_state[T.MA]',\n",
       "     'patient_state[T.MD]',\n",
       "     'patient_state[T.ME]',\n",
       "     'patient_state[T.MI]',\n",
       "     'patient_state[T.MN]',\n",
       "     'patient_state[T.MO]',\n",
       "     'patient_state[T.MS]',\n",
       "     'patient_state[T.MT]',\n",
       "     'patient_state[T.NC]',\n",
       "     'patient_state[T.ND]',\n",
       "     'patient_state[T.NE]',\n",
       "     'patient_state[T.NH]',\n",
       "     'patient_state[T.NJ]',\n",
       "     'patient_state[T.NM]',\n",
       "     'patient_state[T.NV]',\n",
       "     'patient_state[T.NY]',\n",
       "     'patient_state[T.OH]',\n",
       "     'patient_state[T.OK]',\n",
       "     'patient_state[T.OR]',\n",
       "     'patient_state[T.PA]',\n",
       "     'patient_state[T.RI]',\n",
       "     'patient_state[T.SC]',\n",
       "     'patient_state[T.SD]',\n",
       "     'patient_state[T.TN]',\n",
       "     'patient_state[T.TX]',\n",
       "     'patient_state[T.UT]',\n",
       "     'patient_state[T.VA]',\n",
       "     'patient_state[T.VT]',\n",
       "     'patient_state[T.WA]',\n",
       "     'patient_state[T.WI]',\n",
       "     'patient_state[T.WV]',\n",
       "     'patient_state[T.WY]',\n",
       "     'gender[T.Female]',\n",
       "     'Fructose_int',\n",
       "     'Cancer',\n",
       "     'Milk_protein_int',\n",
       "     'Common_var_imm_def',\n",
       "     'agecat4',\n",
       "     'ethnicity_cat6',\n",
       "     'Congenital_mal_m',\n",
       "     'Pancreatic_ins',\n",
       "     'ethnicity_cat2',\n",
       "     'Gauchers_dis',\n",
       "     'Adrenal_ins',\n",
       "     'Lactose_int',\n",
       "     'Inborn_err_met',\n",
       "     'total_outpatient_cost',\n",
       "     'Congenital_HD',\n",
       "     'Cirrhosis',\n",
       "     'Chronic_ren_ins',\n",
       "     'Malabs',\n",
       "     'Urea_cyc_dis',\n",
       "     'Technology_dep',\n",
       "     'inpatient_visit',\n",
       "     'Phenylketonuria',\n",
       "     'EoE',\n",
       "     'agedays',\n",
       "     'region_cat5',\n",
       "     'oop_inpatient_cost',\n",
       "     'oop_outpatient_cost',\n",
       "     'ethnicity_cat5',\n",
       "     'Esophageal_atresia',\n",
       "     'Congenital_mal_n',\n",
       "     'ethnicity_cat4',\n",
       "     'Maple_syr_urine_dis',\n",
       "     'ethnicity_cat1',\n",
       "     'Diabetes_ins',\n",
       "     'payert_cat1',\n",
       "     'Slow_fetal_growth',\n",
       "     'Fetal_alc_syn',\n",
       "     'total_inpatient_visit',\n",
       "     'agecat1',\n",
       "     'ethnicity_cat3',\n",
       "     'oop_positive_exp',\n",
       "     'agecat2',\n",
       "     'Hyper_Ige_syn',\n",
       "     'region_cat3',\n",
       "     'Congenital_mal_c',\n",
       "     'Sickle_cell',\n",
       "     'agecat3',\n",
       "     'region_cat4',\n",
       "     'Kartagener_syn',\n",
       "     'payert_cat3',\n",
       "     'Brain_injury',\n",
       "     'Renal_tub',\n",
       "     'Seizure',\n",
       "     'region_cat2',\n",
       "     'total_inpatient_cost',\n",
       "     'Gastro_eso_reflux',\n",
       "     'payert_cat2',\n",
       "     'Hypothyroidism',\n",
       "     'region_cat1',\n",
       "     'Growth_horm_def']\n",
       "  Terms:\n",
       "    'Intercept' (column 0)\n",
       "    'patient_state' (columns 1:51)\n",
       "    'gender' (column 51)\n",
       "    'Fructose_int' (column 52)\n",
       "    'Cancer' (column 53)\n",
       "    'Milk_protein_int' (column 54)\n",
       "    'Common_var_imm_def' (column 55)\n",
       "    'agecat4' (column 56)\n",
       "    'ethnicity_cat6' (column 57)\n",
       "    'Congenital_mal_m' (column 58)\n",
       "    'Pancreatic_ins' (column 59)\n",
       "    'ethnicity_cat2' (column 60)\n",
       "    'Gauchers_dis' (column 61)\n",
       "    'Adrenal_ins' (column 62)\n",
       "    'Lactose_int' (column 63)\n",
       "    'Inborn_err_met' (column 64)\n",
       "    'total_outpatient_cost' (column 65)\n",
       "    'Congenital_HD' (column 66)\n",
       "    'Cirrhosis' (column 67)\n",
       "    'Chronic_ren_ins' (column 68)\n",
       "    'Malabs' (column 69)\n",
       "    'Urea_cyc_dis' (column 70)\n",
       "    'Technology_dep' (column 71)\n",
       "    'inpatient_visit' (column 72)\n",
       "    'Phenylketonuria' (column 73)\n",
       "    'EoE' (column 74)\n",
       "    'agedays' (column 75)\n",
       "    'region_cat5' (column 76)\n",
       "    'oop_inpatient_cost' (column 77)\n",
       "    'oop_outpatient_cost' (column 78)\n",
       "    'ethnicity_cat5' (column 79)\n",
       "    'Esophageal_atresia' (column 80)\n",
       "    'Congenital_mal_n' (column 81)\n",
       "    'ethnicity_cat4' (column 82)\n",
       "    'Maple_syr_urine_dis' (column 83)\n",
       "    'ethnicity_cat1' (column 84)\n",
       "    'Diabetes_ins' (column 85)\n",
       "    'payert_cat1' (column 86)\n",
       "    'Slow_fetal_growth' (column 87)\n",
       "    'Fetal_alc_syn' (column 88)\n",
       "    'total_inpatient_visit' (column 89)\n",
       "    'agecat1' (column 90)\n",
       "    'ethnicity_cat3' (column 91)\n",
       "    'oop_positive_exp' (column 92)\n",
       "    'agecat2' (column 93)\n",
       "    'Hyper_Ige_syn' (column 94)\n",
       "    'region_cat3' (column 95)\n",
       "    'Congenital_mal_c' (column 96)\n",
       "    'Sickle_cell' (column 97)\n",
       "    'agecat3' (column 98)\n",
       "    'region_cat4' (column 99)\n",
       "    'Kartagener_syn' (column 100)\n",
       "    'payert_cat3' (column 101)\n",
       "    'Brain_injury' (column 102)\n",
       "    'Renal_tub' (column 103)\n",
       "    'Seizure' (column 104)\n",
       "    'region_cat2' (column 105)\n",
       "    'total_inpatient_cost' (column 106)\n",
       "    'Gastro_eso_reflux' (column 107)\n",
       "    'payert_cat2' (column 108)\n",
       "    'Hypothyroidism' (column 109)\n",
       "    'region_cat1' (column 110)\n",
       "    'Growth_horm_def' (column 111)\n",
       "  (to view full data, use np.asarray(this_obj))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e37d825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set default figure size to be larger\n",
    "## this may only work in matplotlib 2.0+!\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = [10.0, 6.0]\n",
    "matplotlib.rcParams['font.serif'] = \"Georgia\"\n",
    "matplotlib.rcParams['font.family'] = \"serif\"\n",
    "\n",
    "## Enable multiple outputs from jupyter cells\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5c21262",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split Data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,\n",
    "test_size=0.20,\n",
    "random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6468b45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164659, 112)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(41165, 112)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Confirm dimensions of covariate matrix\n",
    "X_train.shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be6b613e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(164659, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(41165, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Confirm dimensions of target matrix\n",
    "y_train.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53523956",
   "metadata": {},
   "source": [
    "# Defining Function to print detailed classification results\n",
    "Before we run any model lets define a function to print full classification report and then create a dictionary to store results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c7883b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(X_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ac20ba",
   "metadata": {},
   "source": [
    "# First Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99c49210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='none', solver='newton-cg')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import linear model\n",
    "from sklearn import linear_model\n",
    "\n",
    "## Define model parameters\n",
    "clf = linear_model.LogisticRegression(penalty='none', solver='newton-cg')\n",
    "\n",
    "# Penalty - see here https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "\n",
    "## fit model using data with .fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23ca5092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.96068493e-01, -6.50058809e-02,  4.02520563e-02,\n",
       "         4.31888354e-02, -1.90229357e-01, -3.48804701e-01,\n",
       "         4.70787330e-03, -1.69419675e-01, -4.43186371e-02,\n",
       "        -2.17659075e-01,  9.21805990e-02,  2.25939147e-01,\n",
       "        -1.75686305e-02, -2.09089559e-01, -1.93148126e-01,\n",
       "         9.68148245e-02, -3.41344179e-02,  2.97921855e-01,\n",
       "         1.93088015e-01, -4.59299420e-01, -2.68083909e-01,\n",
       "         2.41858424e-01, -1.11812605e-01, -1.16189871e-01,\n",
       "         2.28014605e-01,  1.02577376e-01,  1.00357834e-01,\n",
       "        -7.12450190e-02,  1.78098530e-01,  6.68757453e-02,\n",
       "        -5.84194195e-02, -1.97513230e-01, -2.04356567e-03,\n",
       "        -1.56542492e-01,  4.16437185e-02,  8.78164891e-02,\n",
       "        -3.74927333e-02,  2.54905524e-01, -9.08244336e-03,\n",
       "         6.57032153e-02,  6.28830520e-02, -1.78239330e-02,\n",
       "        -1.40146409e-02, -1.03938833e-01,  8.15474152e-02,\n",
       "        -1.92485041e-01,  1.86872805e-01,  1.86650972e-01,\n",
       "        -3.20812434e-01,  3.09538563e-01,  2.52947834e-01,\n",
       "        -2.57536555e-01, -8.87332416e-03,  1.51266747e-01,\n",
       "        -3.51661186e-01, -1.31233567e-01, -3.10561392e-01,\n",
       "        -2.24638113e-01, -1.91693148e-01, -3.38350628e-01,\n",
       "        -7.19681841e-01,  7.88775418e-02,  2.37358906e-01,\n",
       "        -9.47073142e-02, -2.71347137e-02,  1.00966052e-06,\n",
       "        -1.51243723e-01, -4.93223336e-02, -1.27775949e-01,\n",
       "        -2.82732232e-01,  4.64267466e-02, -3.85544005e-01,\n",
       "         1.06910800e-01, -8.50331984e-03, -2.55536043e-01,\n",
       "         1.08734121e-04, -2.73448266e-01, -1.99704815e-06,\n",
       "         5.87690935e-06,  7.20804448e-02, -9.49668685e-02,\n",
       "        -7.03537903e-02,  2.44063410e-01, -4.36693650e-02,\n",
       "         2.02732765e-01,  5.27719930e-01, -3.46326764e-01,\n",
       "         3.88772846e-02,  6.10536107e-02,  2.76507148e-02,\n",
       "        -2.84967526e-01, -2.70625159e-01,  1.36201212e-01,\n",
       "         3.47753493e-02,  5.83605482e-02,  0.00000000e+00,\n",
       "        -2.15097274e-01, -4.76738044e-01, -1.35314924e-01,\n",
       "        -8.52219267e-02, -2.11331696e-02, -1.60793627e-01,\n",
       "        -1.80812296e-01, -1.49662374e-02,  1.29249981e-01,\n",
       "        -1.53869824e-01, -6.40073593e-07,  3.70534967e-01,\n",
       "        -1.88948102e-01,  8.85684393e-01, -1.83528476e-01,\n",
       "        -6.44183382e-01]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get coefficients\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17349977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.844964441664288"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get accuracy score?\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04ff30a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[139129,      3],\n",
       "       [ 25525,      2]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get confusion matrix on training data\n",
    "cf1 = confusion_matrix(y_train, clf.predict(X_train))\n",
    "cf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "259dd910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34627,     1],\n",
       "       [ 6532,     5]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get confusion matrix on test data\n",
    "cf1_test = confusion_matrix(y_test, clf.predict(X_test))\n",
    "cf1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30f5523a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy was 0.845\n"
     ]
    }
   ],
   "source": [
    "## identify accuracy by hand from confusion matrix\n",
    "accuracy = (cf1[0, 0] + cf1[1, 1])/np.sum(cf1)\n",
    "print(f'Model accuracy was {accuracy:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92a4c2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000283930789894"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## balanced accuracy\n",
    "balanced_accuracy_score(y_train, clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f052959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.595229134262695e-05"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get kappa\n",
    "sklearn.metrics.cohen_kappa_score(y_train,\n",
    "clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d48ed559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      1.00      0.92    139132\n",
      "         1.0       0.40      0.00      0.00     25527\n",
      "\n",
      "    accuracy                           0.84    164659\n",
      "   macro avg       0.62      0.50      0.46    164659\n",
      "weighted avg       0.78      0.84      0.77    164659\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## get many classification metrics\n",
    "print(sklearn.metrics.classification_report(y_train, clf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1da110",
   "metadata": {},
   "source": [
    "# Creating Dictionary to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c9fd83a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dict to store all these results:\n",
    "result_scores = {}\n",
    "\n",
    "## Score the Model on Training and Testing Set\n",
    "result_scores['Logistic'] = \\\n",
    "(accuracy_score(y_train, clf.predict(X_train)),\n",
    "accuracy_score(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b187a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Function to Print Results\n",
    "def get_results(x1):\n",
    "    print(\"\\n{0:20} {1:4} {2:4}\".format('Model','Train','Test'))\n",
    "    print('-------------------------------------------')\n",
    "    for i in x1.keys():\n",
    "        print(\"{0:20} {1:<6.4} {2:<6.4}\".format(i,x1[i][0],x1[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e6b3dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                Train Test\n",
      "-------------------------------------------\n",
      "Logistic             0.845  0.8413\n"
     ]
    }
   ],
   "source": [
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63888c0c",
   "metadata": {},
   "source": [
    "# Logistic Regression with L1 Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6bff1c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[139127,      5],\n",
       "       [ 25518,      9]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Logistic Regression with l1 penalty\n",
    "clf = linear_model.LogisticRegression(penalty='l1', # specify penalty\n",
    "C=1,\n",
    "solver='liblinear')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "## get confusion matrix\n",
    "confusion_matrix(y_train, clf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "761dabb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8449948074505493"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.000534884940184055"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92    139132\n",
      "         1.0       0.64      0.00      0.00     25527\n",
      "\n",
      "    accuracy                           0.84    164659\n",
      "   macro avg       0.74      0.50      0.46    164659\n",
      "weighted avg       0.81      0.84      0.77    164659\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      1.00      0.91     34628\n",
      "         1.0       0.86      0.00      0.00      6537\n",
      "\n",
      "    accuracy                           0.84     41165\n",
      "   macro avg       0.85      0.50      0.46     41165\n",
      "weighted avg       0.84      0.84      0.77     41165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## get accuracy\n",
    "accuracy_score(y_train,clf.predict(X_train))\n",
    "## Get kappa\n",
    "sklearn.metrics.cohen_kappa_score(y_train,clf.predict(X_train))\n",
    "## get classification metrics\n",
    "print(sklearn.metrics.classification_report(y_train, clf.predict(X_train)))\n",
    "## get classification metrics on test\n",
    "print(sklearn.metrics.classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b2327fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                Train Test\n",
      "-------------------------------------------\n",
      "Logistic             0.845  0.8413\n",
      "Logistic_L1          0.845  0.8413\n"
     ]
    }
   ],
   "source": [
    "## Score the Model on Training and Testing Set\n",
    "result_scores['Logistic_L1'] = \\\n",
    "(accuracy_score(y_train, clf.predict(X_train)),\n",
    "accuracy_score(y_test, clf.predict(X_test)))\n",
    "\n",
    "# Save the Model results in a function\n",
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8812f8e",
   "metadata": {},
   "source": [
    "# Scaling/Pipeline\n",
    "Scaling is used when we use shrinkage methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "415e84f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scale', StandardScaler()),\n",
       "                ('LASSO',\n",
       "                 LogisticRegression(C=0.5, penalty='l1', solver='liblinear'))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## LASSO regression, set alpha\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "clf = linear_model.LogisticRegression(penalty='l1',\n",
    "C=0.5,\n",
    "solver='liblinear')\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "pipe1 = Pipeline([(\"scale\", scaler), (\"LASSO\", clf)])\n",
    "pipe1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff5ef772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.844964441664288"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Score on training data\n",
    "pipe1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0aec803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8413700959553019"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Score on testing data\n",
    "pipe1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08cdc676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                Train Test\n",
      "-------------------------------------------\n",
      "Logistic             0.845  0.8413\n",
      "Logistic_L1          0.845  0.8413\n",
      "Logistic_L1_0.5      0.845  0.8414\n"
     ]
    }
   ],
   "source": [
    "## Score the Model on Training and Testing Set\n",
    "result_scores['Logistic_L1_0.5'] = \\\n",
    "(accuracy_score(y_train, pipe1.predict(X_train)),\n",
    "accuracy_score(y_test, pipe1.predict(X_test)))\n",
    "\n",
    "# Store Model Results\n",
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4ee67d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bd3af89",
   "metadata": {},
   "source": [
    "# Selecting Parameters through Cross Validation\n",
    "C is the inverse of regulatization strength in LASSO: Smaller C means stronger Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ed3a2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scale', StandardScaler()),\n",
       "                ('LASSO',\n",
       "                 LogisticRegressionCV(Cs=[0.01, 0.05, 0.1, 0.15, 0.2, 0.5,\n",
       "                                          1]))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Select the alpha through cross validation (leave one out)\n",
    "clf = linear_model.LogisticRegressionCV(Cs=[0.01, 0.05, 0.1, 0.15, 0.2, 0.5, 1])\n",
    "scaler = preprocessing.StandardScaler()\n",
    "pipe2 = Pipeline([(\"scale\", scaler), (\"LASSO\", clf)])\n",
    "pipe2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "358d0eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2.named_steps['LASSO'].C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5888192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8449705148215403"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8413700959553019"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Examine the score of the model on training data\n",
    "pipe2.score(X_train, y_train)\n",
    "\n",
    "## Score on validation/test data\n",
    "pipe2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ef36dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                Train Test\n",
      "-------------------------------------------\n",
      "Logistic             0.845  0.8413\n",
      "Logistic_L1          0.845  0.8413\n",
      "Logistic_L1_0.5      0.845  0.8414\n",
      "Logistic_L1_C        0.845  0.8414\n"
     ]
    }
   ],
   "source": [
    "## Score the Model on Training and Testing Set\n",
    "result_scores['Logistic_L1_C'] = \\\n",
    "(accuracy_score(y_train, pipe2.predict(X_train)),\n",
    "accuracy_score(y_test, pipe2.predict(X_test)))\n",
    "\n",
    "# Store Model Results\n",
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d235ae37",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fc09951a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=3000, random_state=42)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[139130,      2],\n",
       "       [    15,  25512]], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Fit Random Forest (Scaling is not necessary)\n",
    "\n",
    "from sklearn import ensemble\n",
    "\n",
    "from sklearn import ensemble\n",
    "clf = ensemble.RandomForestClassifier(random_state=42, max_depth=3000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "## get confusion matrix on training data\n",
    "confusion_matrix(y_train, clf.predict(X_train))\n",
    "# This produces great predictive model for training data, showing overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a2ba0efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33985,   643],\n",
       "       [ 6359,   178]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get confusion matrix on test data\n",
    "confusion_matrix(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc073bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                Train Test\n",
      "-------------------------------------------\n",
      "Logistic             0.845  0.8413\n",
      "Logistic_L1          0.845  0.8413\n",
      "Logistic_L1_0.5      0.845  0.8414\n",
      "Logistic_L1_C        0.845  0.8414\n",
      "RandomForest         0.9999 0.8299\n"
     ]
    }
   ],
   "source": [
    "## Score the Model on Training and Testing Set\n",
    "result_scores['RandomForest'] = \\\n",
    "(accuracy_score(y_train, clf.predict(X_train)),\n",
    "accuracy_score(y_test, clf.predict(X_test)))\n",
    "\n",
    "# Store Model Results\n",
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711689fb",
   "metadata": {},
   "source": [
    "# Random Forest with Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "67926452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [None, 3, 10, 1000, 3000,\n",
       "                                                      5000],\n",
       "                                        'max_features': [0.5, 1, 'sqrt',\n",
       "                                                         'auto'],\n",
       "                                        'max_samples': [10000],\n",
       "                                        'min_samples_leaf': array([  1,   3,   5,   7,   9,  11,  13,  15,  17,  19,  21,  23,  25,\n",
       "        27,  29,  31,  33,  35,  37,  39,  41,  43,  45,  47,  49,  51,\n",
       "        53,  55,  57,  59,  61,  63,  65,  67...\n",
       "       886, 888, 890, 892, 894, 896, 898, 900, 902, 904, 906, 908, 910,\n",
       "       912, 914, 916, 918, 920, 922, 924, 926, 928, 930, 932, 934, 936,\n",
       "       938, 940, 942, 944, 946, 948, 950, 952, 954, 956, 958, 960, 962,\n",
       "       964, 966, 968, 970, 972, 974, 976, 978, 980, 982, 984, 986, 988,\n",
       "       990, 992, 994, 996, 998]),\n",
       "                                        'n_estimators': array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130,\n",
       "       140, 150, 160, 170, 180, 190])},\n",
       "                   return_train_score=True, verbose=True)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid = {\"n_estimators\": np.arange(10, 200, 10),\n",
    "           \"bootstrap\": [True, False],\n",
    "           \"max_depth\": [None, 3, 10, 1000, 3000, 5000],\n",
    "           \"min_samples_split\": np.arange(2, 1000, 2),\n",
    "           \"min_samples_leaf\": np.arange(1, 1000, 2),\n",
    "           \"max_features\": [0.5, 1, \"sqrt\", \"auto\"],\n",
    "           \"max_samples\": [10000]}\n",
    "\n",
    "# Instantiate RandomizedSearchCV model\n",
    "rs_model = RandomizedSearchCV(RandomForestClassifier(n_jobs=-1, random_state=42),\n",
    "                              param_distributions=rf_grid,\n",
    "                              n_iter=10,\n",
    "                              cv=5,\n",
    "                              verbose=True,\n",
    "                              return_train_score = True,\n",
    "                              refit=True)\n",
    "# fit\n",
    "rs_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "71a7783f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 130,\n",
       " 'min_samples_split': 338,\n",
       " 'min_samples_leaf': 559,\n",
       " 'max_samples': 10000,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 10,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "37aede8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_samples</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_bootstrap</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.539201</td>\n",
       "      <td>0.130640</td>\n",
       "      <td>0.125647</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>130</td>\n",
       "      <td>338</td>\n",
       "      <td>559</td>\n",
       "      <td>10000</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 130, 'min_samples_split': 338...</td>\n",
       "      <td>0.844953</td>\n",
       "      <td>0.844953</td>\n",
       "      <td>0.844984</td>\n",
       "      <td>0.844984</td>\n",
       "      <td>0.844979</td>\n",
       "      <td>0.844971</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844975</td>\n",
       "      <td>0.844975</td>\n",
       "      <td>0.844967</td>\n",
       "      <td>0.844967</td>\n",
       "      <td>0.844968</td>\n",
       "      <td>0.844971</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.747026</td>\n",
       "      <td>0.039232</td>\n",
       "      <td>0.124550</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>110</td>\n",
       "      <td>142</td>\n",
       "      <td>971</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>{'n_estimators': 110, 'min_samples_split': 142...</td>\n",
       "      <td>0.844953</td>\n",
       "      <td>0.844953</td>\n",
       "      <td>0.844984</td>\n",
       "      <td>0.844984</td>\n",
       "      <td>0.844979</td>\n",
       "      <td>0.844971</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844975</td>\n",
       "      <td>0.844975</td>\n",
       "      <td>0.844967</td>\n",
       "      <td>0.844967</td>\n",
       "      <td>0.844968</td>\n",
       "      <td>0.844971</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.894540</td>\n",
       "      <td>0.066865</td>\n",
       "      <td>0.125815</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>10</td>\n",
       "      <td>956</td>\n",
       "      <td>507</td>\n",
       "      <td>10000</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 10, 'min_samples_split': 956,...</td>\n",
       "      <td>0.844953</td>\n",
       "      <td>0.844953</td>\n",
       "      <td>0.844984</td>\n",
       "      <td>0.844984</td>\n",
       "      <td>0.844979</td>\n",
       "      <td>0.844971</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844975</td>\n",
       "      <td>0.844975</td>\n",
       "      <td>0.844967</td>\n",
       "      <td>0.844967</td>\n",
       "      <td>0.844968</td>\n",
       "      <td>0.844971</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.690829</td>\n",
       "      <td>0.047724</td>\n",
       "      <td>0.124738</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>100</td>\n",
       "      <td>536</td>\n",
       "      <td>595</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>{'n_estimators': 100, 'min_samples_split': 536...</td>\n",
       "      <td>0.844953</td>\n",
       "      <td>0.844953</td>\n",
       "      <td>0.844984</td>\n",
       "      <td>0.844984</td>\n",
       "      <td>0.844979</td>\n",
       "      <td>0.844971</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844975</td>\n",
       "      <td>0.844975</td>\n",
       "      <td>0.844967</td>\n",
       "      <td>0.844967</td>\n",
       "      <td>0.844968</td>\n",
       "      <td>0.844971</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.756272</td>\n",
       "      <td>0.048150</td>\n",
       "      <td>0.124493</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>90</td>\n",
       "      <td>562</td>\n",
       "      <td>419</td>\n",
       "      <td>10000</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>{'n_estimators': 90, 'min_samples_split': 562,...</td>\n",
       "      <td>0.844953</td>\n",
       "      <td>0.844953</td>\n",
       "      <td>0.844984</td>\n",
       "      <td>0.844984</td>\n",
       "      <td>0.844979</td>\n",
       "      <td>0.844971</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844975</td>\n",
       "      <td>0.844975</td>\n",
       "      <td>0.844967</td>\n",
       "      <td>0.844967</td>\n",
       "      <td>0.844968</td>\n",
       "      <td>0.844971</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.598834</td>\n",
       "      <td>0.085638</td>\n",
       "      <td>0.124896</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>120</td>\n",
       "      <td>630</td>\n",
       "      <td>893</td>\n",
       "      <td>10000</td>\n",
       "      <td>auto</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 120, 'min_samples_split': 630...</td>\n",
       "      <td>0.844953</td>\n",
       "      <td>0.844953</td>\n",
       "      <td>0.844984</td>\n",
       "      <td>0.844984</td>\n",
       "      <td>0.844979</td>\n",
       "      <td>0.844971</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844975</td>\n",
       "      <td>0.844975</td>\n",
       "      <td>0.844967</td>\n",
       "      <td>0.844967</td>\n",
       "      <td>0.844968</td>\n",
       "      <td>0.844971</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.013862</td>\n",
       "      <td>0.057995</td>\n",
       "      <td>0.125864</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>140</td>\n",
       "      <td>496</td>\n",
       "      <td>689</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 140, 'min_samples_split': 496...</td>\n",
       "      <td>0.844953</td>\n",
       "      <td>0.844953</td>\n",
       "      <td>0.844984</td>\n",
       "      <td>0.844984</td>\n",
       "      <td>0.844979</td>\n",
       "      <td>0.844971</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844975</td>\n",
       "      <td>0.844975</td>\n",
       "      <td>0.844967</td>\n",
       "      <td>0.844967</td>\n",
       "      <td>0.844968</td>\n",
       "      <td>0.844971</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.197236</td>\n",
       "      <td>0.055278</td>\n",
       "      <td>0.127267</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>160</td>\n",
       "      <td>648</td>\n",
       "      <td>419</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 160, 'min_samples_split': 648...</td>\n",
       "      <td>0.844953</td>\n",
       "      <td>0.844953</td>\n",
       "      <td>0.844984</td>\n",
       "      <td>0.844984</td>\n",
       "      <td>0.844979</td>\n",
       "      <td>0.844971</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844975</td>\n",
       "      <td>0.844975</td>\n",
       "      <td>0.844967</td>\n",
       "      <td>0.844967</td>\n",
       "      <td>0.844968</td>\n",
       "      <td>0.844971</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.711140</td>\n",
       "      <td>0.036685</td>\n",
       "      <td>0.127261</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>70</td>\n",
       "      <td>248</td>\n",
       "      <td>159</td>\n",
       "      <td>10000</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>{'n_estimators': 70, 'min_samples_split': 248,...</td>\n",
       "      <td>0.844953</td>\n",
       "      <td>0.844953</td>\n",
       "      <td>0.844984</td>\n",
       "      <td>0.844984</td>\n",
       "      <td>0.844979</td>\n",
       "      <td>0.844971</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844975</td>\n",
       "      <td>0.844975</td>\n",
       "      <td>0.844967</td>\n",
       "      <td>0.844967</td>\n",
       "      <td>0.844968</td>\n",
       "      <td>0.844971</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.622917</td>\n",
       "      <td>0.066524</td>\n",
       "      <td>0.125939</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>50</td>\n",
       "      <td>602</td>\n",
       "      <td>693</td>\n",
       "      <td>10000</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 50, 'min_samples_split': 602,...</td>\n",
       "      <td>0.844953</td>\n",
       "      <td>0.844953</td>\n",
       "      <td>0.844984</td>\n",
       "      <td>0.844984</td>\n",
       "      <td>0.844979</td>\n",
       "      <td>0.844971</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1</td>\n",
       "      <td>0.844975</td>\n",
       "      <td>0.844975</td>\n",
       "      <td>0.844967</td>\n",
       "      <td>0.844967</td>\n",
       "      <td>0.844968</td>\n",
       "      <td>0.844971</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_n_estimators param_min_samples_split param_min_samples_leaf param_max_samples param_max_features param_max_depth param_bootstrap                                             params  split0_test_score  split1_test_score  split2_test_score  split3_test_score  split4_test_score  mean_test_score  std_test_score  rank_test_score  split0_train_score  split1_train_score  split2_train_score  split3_train_score  split4_train_score  mean_train_score  std_train_score\n",
       "0       5.539201      0.130640         0.125647        0.001253                130                     338                    559             10000               sqrt              10           False  {'n_estimators': 130, 'min_samples_split': 338...           0.844953           0.844953           0.844984           0.844984           0.844979         0.844971        0.000014                1            0.844975            0.844975            0.844967            0.844967            0.844968          0.844971         0.000004\n",
       "1       0.747026      0.039232         0.124550        0.001233                110                     142                    971             10000                  1              10            True  {'n_estimators': 110, 'min_samples_split': 142...           0.844953           0.844953           0.844984           0.844984           0.844979         0.844971        0.000014                1            0.844975            0.844975            0.844967            0.844967            0.844968          0.844971         0.000004\n",
       "2       0.894540      0.066865         0.125815        0.000945                 10                     956                    507             10000               sqrt            1000           False  {'n_estimators': 10, 'min_samples_split': 956,...           0.844953           0.844953           0.844984           0.844984           0.844979         0.844971        0.000014                1            0.844975            0.844975            0.844967            0.844967            0.844968          0.844971         0.000004\n",
       "3       0.690829      0.047724         0.124738        0.000704                100                     536                    595             10000                  1              10            True  {'n_estimators': 100, 'min_samples_split': 536...           0.844953           0.844953           0.844984           0.844984           0.844979         0.844971        0.000014                1            0.844975            0.844975            0.844967            0.844967            0.844968          0.844971         0.000004\n",
       "4       0.756272      0.048150         0.124493        0.001238                 90                     562                    419             10000               sqrt            None            True  {'n_estimators': 90, 'min_samples_split': 562,...           0.844953           0.844953           0.844984           0.844984           0.844979         0.844971        0.000014                1            0.844975            0.844975            0.844967            0.844967            0.844968          0.844971         0.000004\n",
       "5       2.598834      0.085638         0.124896        0.001133                120                     630                    893             10000               auto               3           False  {'n_estimators': 120, 'min_samples_split': 630...           0.844953           0.844953           0.844984           0.844984           0.844979         0.844971        0.000014                1            0.844975            0.844975            0.844967            0.844967            0.844968          0.844971         0.000004\n",
       "6       1.013862      0.057995         0.125864        0.000747                140                     496                    689             10000                  1              10           False  {'n_estimators': 140, 'min_samples_split': 496...           0.844953           0.844953           0.844984           0.844984           0.844979         0.844971        0.000014                1            0.844975            0.844975            0.844967            0.844967            0.844968          0.844971         0.000004\n",
       "7       1.197236      0.055278         0.127267        0.000481                160                     648                    419             10000                  1            5000           False  {'n_estimators': 160, 'min_samples_split': 648...           0.844953           0.844953           0.844984           0.844984           0.844979         0.844971        0.000014                1            0.844975            0.844975            0.844967            0.844967            0.844968          0.844971         0.000004\n",
       "8       0.711140      0.036685         0.127261        0.000523                 70                     248                    159             10000               sqrt            None            True  {'n_estimators': 70, 'min_samples_split': 248,...           0.844953           0.844953           0.844984           0.844984           0.844979         0.844971        0.000014                1            0.844975            0.844975            0.844967            0.844967            0.844968          0.844971         0.000004\n",
       "9       2.622917      0.066524         0.125939        0.000839                 50                     602                    693             10000               auto            1000           False  {'n_estimators': 50, 'min_samples_split': 602,...           0.844953           0.844953           0.844984           0.844984           0.844979         0.844971        0.000014                1            0.844975            0.844975            0.844967            0.844967            0.844968          0.844971         0.000004"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_score = pd.DataFrame(rs_model.cv_results_)\n",
    "cv_result_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "68bc43b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[139132,      0],\n",
       "       [ 25527,      0]], dtype=int64)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[34628,     0],\n",
       "       [ 6537,     0]], dtype=int64)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, rs_model.predict(X_train))\n",
    "confusion_matrix(y_test, rs_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "226c2238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                Train Test\n",
      "-------------------------------------------\n",
      "Logistic             0.845  0.8413\n",
      "Logistic_L1          0.845  0.8413\n",
      "Logistic_L1_0.5      0.845  0.8414\n",
      "Logistic_L1_C        0.845  0.8414\n",
      "RandomForest         0.9999 0.8299\n",
      "RandomForest_CV      0.845  0.8412\n"
     ]
    }
   ],
   "source": [
    "## Score the Model on Training and Testing Set\n",
    "result_scores['RandomForest_CV'] = \\\n",
    "(accuracy_score(y_train, rs_model.predict(X_train)),\n",
    "accuracy_score(y_test, rs_model.predict(X_test)))\n",
    "\n",
    "# Store Model Results\n",
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ee94cb",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "528c20d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=0)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[139131,      1],\n",
       "       [ 25505,     22]], dtype=int64)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(random_state=0)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "confusion_matrix(y_train,gbc.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c5e2e48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                Train Test\n",
      "-------------------------------------------\n",
      "Logistic             0.845  0.8413\n",
      "Logistic_L1          0.845  0.8413\n",
      "Logistic_L1_0.5      0.845  0.8414\n",
      "Logistic_L1_C        0.845  0.8414\n",
      "RandomForest         0.9999 0.8299\n",
      "RandomForest_CV      0.845  0.8412\n",
      "GBC                  0.8451 0.8412\n"
     ]
    }
   ],
   "source": [
    "## Score the Model on Training and Testing Set\n",
    "result_scores['GBC'] = \\\n",
    "(sklearn.metrics.accuracy_score(y_train, gbc.predict(X_train)),\n",
    "sklearn.metrics.accuracy_score(y_test, gbc.predict(X_test)))\n",
    "\n",
    "# Store Model Results\n",
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927f1024",
   "metadata": {},
   "source": [
    "# Support Vector Machine Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "131b1d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(loss='hinge')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Kernel\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(loss='hinge', dual=True)\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a9e62b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scale', StandardScaler()),\n",
       "                ('LASSO', LinearSVC(loss='hinge'))])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## LASSO regression, set alpha\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC(loss='hinge', dual=True)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "pipe1 = Pipeline([(\"scale\", scaler), (\"LASSO\", clf)])\n",
    "pipe1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d7352500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84491585640627"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8411757561034859"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1.score(X_train, y_train)\n",
    "\n",
    "## Score on validation/test data\n",
    "pipe1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4dc3ddea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[139104,     28],\n",
       "       [ 25508,     19]], dtype=int64)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train,pipe1.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d0055a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34623,     5],\n",
       "       [ 6533,     4]], dtype=int64)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pipe1.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b9c0d7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 84.49%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                     0.0           1.0  accuracy      macro avg   weighted avg\n",
      "precision       0.845042      0.404255  0.844916       0.624648       0.776707\n",
      "recall          0.999799      0.000744  0.844916       0.500272       0.844916\n",
      "f1-score        0.915929      0.001486  0.844916       0.458708       0.774164\n",
      "support    139132.000000  25527.000000  0.844916  164659.000000  164659.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[139104     28]\n",
      " [ 25508     19]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 84.12%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    0.0          1.0  accuracy     macro avg  weighted avg\n",
      "precision      0.841263     0.444444  0.841176      0.642853      0.778248\n",
      "recall         0.999856     0.000612  0.841176      0.500234      0.841176\n",
      "f1-score       0.913728     0.001222  0.841176      0.457475      0.768823\n",
      "support    34628.000000  6537.000000  0.841176  41165.000000  41165.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[34623     5]\n",
      " [ 6533     4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_score(pipe1, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(pipe1, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1f0c2d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                Train Test\n",
      "-------------------------------------------\n",
      "Logistic             0.845  0.8413\n",
      "Logistic_L1          0.845  0.8413\n",
      "Logistic_L1_0.5      0.845  0.8414\n",
      "Logistic_L1_C        0.845  0.8414\n",
      "RandomForest         0.9999 0.8299\n",
      "RandomForest_CV      0.845  0.8412\n",
      "GBC                  0.8451 0.8412\n",
      "SVC Linear           0.8449 0.8412\n"
     ]
    }
   ],
   "source": [
    "## Score the Model on Training and Testing Set\n",
    "result_scores['SVC Linear'] = \\\n",
    "(sklearn.metrics.accuracy_score(y_train, pipe1.predict(X_train)),\n",
    "sklearn.metrics.accuracy_score(y_test, pipe1.predict(X_test)))\n",
    "\n",
    "# Store Model Results\n",
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527687c3",
   "metadata": {},
   "source": [
    "# Adding xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "70e71fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost's prediction accuracy is: 84.09\n",
      "Time consumed for training: 8.828\n",
      "Time consumed for prediction: 0.03813 seconds\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=100)\n",
    "\n",
    "training_start = time.perf_counter()\n",
    "xgb= xgb.fit(X_train, y_train)\n",
    "training_end = time.perf_counter()\n",
    "\n",
    "prediction_start = time.perf_counter()\n",
    "preds = xgb.predict(X_test)\n",
    "prediction_end = time.perf_counter()\n",
    "\n",
    "# Save rounded values in predictions\n",
    "predictions = [round(value) for value in preds]\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "acc_xgb = accuracy*100\n",
    "\n",
    "#print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "#acc_xgb = (preds == y_test).sum().astype(float) / len(preds)*100\n",
    "\n",
    "xgb_train_time = training_end-training_start\n",
    "xgb_prediction_time = prediction_end-prediction_start\n",
    "\n",
    "print(\"XGBoost's prediction accuracy is: %3.2f\" % (acc_xgb))\n",
    "print(\"Time consumed for training: %4.3f\" % (xgb_train_time))\n",
    "print(\"Time consumed for prediction: %6.5f seconds\" % (xgb_prediction_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "47d97fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                Train Test\n",
      "-------------------------------------------\n",
      "Logistic             0.845  0.8413\n",
      "Logistic_L1          0.845  0.8413\n",
      "Logistic_L1_0.5      0.845  0.8414\n",
      "Logistic_L1_C        0.845  0.8414\n",
      "RandomForest         0.9999 0.8299\n",
      "RandomForest_CV      0.845  0.8412\n",
      "GBC                  0.8451 0.8412\n",
      "SVC Linear           0.8449 0.8412\n",
      "XG Boost             0.8467 0.8409\n"
     ]
    }
   ],
   "source": [
    "## Score the Model on Training and Testing Set\n",
    "result_scores['XG Boost'] = \\\n",
    "(sklearn.metrics.accuracy_score(y_train, xgb.predict(X_train)),\n",
    "sklearn.metrics.accuracy_score(y_test, xgb.predict(X_test)))\n",
    "\n",
    "# Store Model Results\n",
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "370e0bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.84446739 0.84477104 0.84471031 0.84392081 0.84398154 0.84434592\n",
      " 0.84452812 0.84428519 0.84458885 0.84476162]\n",
      "Mean: 0.8444360789603762\n",
      "Standard Deviation: 0.0002879543409145578\n"
     ]
    }
   ],
   "source": [
    "# Getting cross validation scores for XGB to see result sensitivity\n",
    "from sklearn.model_selection import cross_val_score\n",
    "xgb_cv = XGBClassifier(n_estimators=100)\n",
    "scores = cross_val_score(xgb_cv, X_train, y_train, cv=10, scoring = \"accuracy\")\n",
    "print(\"Scores:\", scores)\n",
    "print(\"Mean:\", scores.mean())\n",
    "print(\"Standard Deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc756d6",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7de7fa",
   "metadata": {},
   "source": [
    "Overall, the default Random Forest performs the best on training data but not much better performance on test data. It shows an evidence of overfitting. All other classification methods performed in a very similar fashion. More feature engineering such as PCA, Lasso or Ridge regression can be done to improve the model prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3a8db1",
   "metadata": {},
   "source": [
    "# Other methods that I planned to include "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fcb337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Kernel in SVM\n",
    "# Took long time to learn\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#The hyperparameter coef0 controls how much the model is influenced by high degree ploynomials \n",
    "model = SVC(kernel='poly', degree=2, gamma='auto', coef0=1, C=5)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print_score(model, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(model, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30ea27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Score the Model on Training and Testing Set\n",
    "result_scores['SVC Polynomial'] = \\\n",
    "(sklearn.metrics.accuracy_score(y_train, model.predict(X_train)),\n",
    "sklearn.metrics.accuracy_score(y_test, model.predict(X_test)))\n",
    "\n",
    "# Store Model Results\n",
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d042c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing default gamma\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "mod = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "mod.fit(X_train, y_train)\n",
    "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "                ('svc', SVC(gamma='scale'))])\n",
    "\n",
    "#scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "#pipe1 = Pipeline(steps=[('standardscaler', StandardScaler()),\n",
    "  #              ('svc', SVC(gamma='auto'))])\n",
    "\n",
    "#pipe1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ba2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(mod, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(mod, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9454b1d3",
   "metadata": {},
   "source": [
    "# Further Cross Validation under Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c80c4d4",
   "metadata": {},
   "source": [
    "## This takes a while to run! Wasn't able to run this.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## Specify grid\n",
    "parameters = {'n_estimators': [500, 1000],\n",
    "'max_features': [5,10]}\n",
    "\n",
    "## Specify model without hyperparameters\n",
    "rf_model = ensemble.RandomForestClassifier(random_state=32)\n",
    "\n",
    "## Specify search with model\n",
    "clf = GridSearchCV(rf_model,\n",
    "parameters,\n",
    "cv=5,\n",
    "return_train_score=True)\n",
    "clf.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab16f94b",
   "metadata": {},
   "source": [
    "# Manual Cross validation in GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872f93e1",
   "metadata": {},
   "source": [
    "## Specify grid in GBM\n",
    "\n",
    "parameters3 = {'n_estimators': (100,500),\n",
    "'learning_rate':(0.1,0.3)}\n",
    "\n",
    "## Specify model without hyperparameters\n",
    "gbc_model = GradientBoostingClassifier()\n",
    "\n",
    "## Specify search with model\n",
    "gbc2 = GridSearchCV(gbc_model,\n",
    "parameters3,\n",
    "cv=5,\n",
    "return_train_score=True)\n",
    "\n",
    "## Now fit the model\n",
    "gbc2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a62720",
   "metadata": {},
   "source": [
    "## Explore best hyperparameters\n",
    "gbc2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7828ccc",
   "metadata": {},
   "source": [
    "## Score the Model on Training and Testing Set\n",
    "result_scores['GBC2'] = \\\n",
    "(sklearn.metrics.accuracy_score(y_train, gbc2.predict(X_train)),\n",
    "sklearn.metrics.accuracy_score(y_test, gbc2.predict(X_test)))\n",
    "\n",
    "## Store Model Results\n",
    "get_results(result_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
